{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNHP-Y6fZgHf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RO_cyZ1vZgHh"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('jobs_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GCXhp65WZgHk"
   },
   "outputs": [],
   "source": [
    "data = data.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "qAbHurXFZgHm",
    "outputId": "4b3d678f-0fae-42be-b04c-41142d1aaaff",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>jobFunction</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Full Stack PHP Developer</td>\n",
       "      <td>['Engineering - Telecom/Technology', 'IT/Softw...</td>\n",
       "      <td>['Computer Software', 'Marketing and Advertisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CISCO Collaboration Specialist Engineer</td>\n",
       "      <td>['Installation/Maintenance/Repair', 'IT/Softwa...</td>\n",
       "      <td>['Information Technology Services']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Back End-PHP Developer</td>\n",
       "      <td>['Engineering - Telecom/Technology', 'IT/Softw...</td>\n",
       "      <td>['Computer Software', 'Computer Networking']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UX Designer</td>\n",
       "      <td>['Creative/Design/Art', 'IT/Software Developme...</td>\n",
       "      <td>['Computer Software', 'Information Technology ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Java Technical Lead</td>\n",
       "      <td>['Engineering - Telecom/Technology', 'IT/Softw...</td>\n",
       "      <td>['Computer Software', 'Information Technology ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     title  ...                                           industry\n",
       "0                 Full Stack PHP Developer  ...  ['Computer Software', 'Marketing and Advertisi...\n",
       "1  CISCO Collaboration Specialist Engineer  ...                ['Information Technology Services']\n",
       "2            Senior Back End-PHP Developer  ...       ['Computer Software', 'Computer Networking']\n",
       "3                              UX Designer  ...  ['Computer Software', 'Information Technology ...\n",
       "4                      Java Technical Lead  ...  ['Computer Software', 'Information Technology ...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9jcCHNQjCbgh"
   },
   "source": [
    "# processing input Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yx-t1DOKZgHp"
   },
   "outputs": [],
   "source": [
    "# separating words of titles\n",
    "titles=[]\n",
    "for title in data['title']:\n",
    "    titles.append(re.sub(\"[^\\w]\", \" \",  title).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "z5A4DmE4ZgHs",
    "outputId": "1443dd4d-117a-4411-e616-c62654c08227",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Full', 'Stack', 'PHP', 'Developer'],\n",
       " ['CISCO', 'Collaboration', 'Specialist', 'Engineer'],\n",
       " ['Senior', 'Back', 'End', 'PHP', 'Developer'],\n",
       " ['UX', 'Designer'],\n",
       " ['Java', 'Technical', 'Lead']]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4f2KgaLYZgHu"
   },
   "outputs": [],
   "source": [
    "# list of total words in dataset \n",
    "vocab=[]\n",
    "for mystr in data['title']:\n",
    "    vocab += re.sub(\"[^\\w]\", \" \",  mystr).split()\n",
    "for i,word in enumerate(vocab):\n",
    "    vocab[i]=word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gUruDo_2ZgHx",
    "outputId": "7c0a2547-7069-42a2-b504-f942619f283b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36570"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "fWKDvs-3ZgH0",
    "outputId": "2ca2a8f4-7265-45de-abe4-822850f310c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1373"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unique words(no duplicates)\n",
    "len(set(vocab)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbFhV9GNZgH3"
   },
   "outputs": [],
   "source": [
    "# frequency of each word\n",
    "counts = Counter(vocab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-3USGxJZgH5"
   },
   "outputs": [],
   "source": [
    "# sort words by no. of occurrences\n",
    "sorted_vocab = sorted(counts, key=counts.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "2BJFXgsLZgH7",
    "outputId": "a520138c-d4e0-4e02-ed1c-24c3f17bf063"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "developer :  2082\n",
      "senior :  1930\n",
      "engineer :  1388\n",
      "sales :  1305\n",
      "manager :  1225\n",
      "specialist :  1129\n",
      "software :  716\n",
      "marketing :  539\n",
      "executive :  520\n",
      "designer :  518\n"
     ]
    }
   ],
   "source": [
    "for word in sorted_vocab[:10]:\n",
    "    print(word,': ', counts[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OhuUTubWZgH-"
   },
   "source": [
    "  #                vocab cleaning   ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "ILioA_8xZgH_",
    "outputId": "e2051029-41b7-4893-b939-9a2b371a2469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a :  194\n",
      "e :  36\n",
      "r :  27\n",
      "d :  26\n",
      "c :  19\n",
      "1 :  9\n",
      "4 :  7\n",
      "7 :  7\n",
      "s :  6\n",
      "و :  5\n",
      "2 :  5\n",
      "6 :  4\n",
      "i :  2\n",
      "م :  2\n",
      "v :  1\n",
      "8 :  1\n",
      "t :  1\n"
     ]
    }
   ],
   "source": [
    "# Remove one-characters\n",
    "for word in sorted_vocab:\n",
    "    if len(word)==1:\n",
    "        print(word,': ', counts[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "mle4AW7EZgIB",
    "outputId": "90ead871-7762-4172-c6d9-494203644982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1373\n",
      "1356\n"
     ]
    }
   ],
   "source": [
    "print(len(sorted_vocab))\n",
    "for word in sorted_vocab:\n",
    "    if len(word)==1:\n",
    "        sorted_vocab.remove(word)\n",
    "print(len(sorted_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "04PsiUo7ZgIE",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for word in sorted_vocab:\n",
    "    if len(word)==1:\n",
    "        print(word,': ', counts[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNL4AbTEZgIH"
   },
   "source": [
    "# remove Non-English words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-m6Y9yyZgII"
   },
   "outputs": [],
   "source": [
    "def NotEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Mz9vz7OwZgIK",
    "outputId": "b4e48066-aa5f-4e2b-cafb-b64cfca50a95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NotEnglish('يىهسنينثهصثخ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "colab_type": "code",
    "id": "Cv3_nVc3ZgIM",
    "outputId": "a1df5996-02fb-4d4a-d910-5f43a8c56f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مسئول :  8\n",
      "مندوب :  7\n",
      "لغة :  5\n",
      "إداري :  5\n",
      "مدير :  5\n",
      "موظفة :  5\n",
      "سوشيال :  5\n",
      "اونلاين :  5\n",
      "خارجي :  5\n",
      "معلم :  3\n",
      "الشئون :  3\n",
      "français :  3\n",
      "انتاج :  2\n",
      "مجال :  2\n",
      "والاعلان :  2\n",
      "امين :  2\n",
      "امن :  2\n",
      "درسة :  2\n",
      "أطفال :  2\n",
      "دكتور :  1\n",
      "مشغل :  1\n",
      "طوب :  1\n",
      "العلمين :  1\n",
      "مخازن :  1\n",
      "مشرف :  1\n",
      "خراسانات :  1\n",
      "أخصائي :  1\n",
      "إلكتروني :  1\n",
      "pédagogique :  1\n"
     ]
    }
   ],
   "source": [
    "for word in sorted_vocab:\n",
    "    if NotEnglish(word):\n",
    "        print(word,': ', counts[word])\n",
    "        sorted_vocab.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "KpGszF-UZgIT",
    "outputId": "9902d7c2-944e-4a52-f1c7-1d9858081a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1327\n",
      "1316\n"
     ]
    }
   ],
   "source": [
    "print(len(sorted_vocab))\n",
    "for word in sorted_vocab:\n",
    "    if NotEnglish(word):\n",
    "        sorted_vocab.remove(word)\n",
    "print(len(sorted_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "CPIqPPT5ZgIY",
    "outputId": "112bb6c5-7e86-4da6-d986-2564d1913e24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1316\n",
      "1312\n"
     ]
    }
   ],
   "source": [
    "print(len(sorted_vocab))\n",
    "for word in sorted_vocab:\n",
    "    if NotEnglish(word):\n",
    "        sorted_vocab.remove(word)\n",
    "print(len(sorted_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22ea_rGRZgIb"
   },
   "outputs": [],
   "source": [
    "for word in sorted_vocab:\n",
    "    if NotEnglish(word):\n",
    "        print(word,': ', counts[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nUijEbenZgIe",
    "outputId": "4839d135-fe62-4a84-9d90-21649835f472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312\n"
     ]
    }
   ],
   "source": [
    "print(len(sorted_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w4Uxs7oCZgIi"
   },
   "source": [
    "# remove places and cities  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4JA3WkVZgIj"
   },
   "outputs": [],
   "source": [
    "places = ['alexandria','cairo','tunisia','german','indonesia','saudi','tanta','egypt','egypt',\n",
    "          'dubai','hurghada','dokki','monufya','brazil','mohandessin','damietta',\n",
    "          'ukraine','turkey','maadi','mansoura','heliopolis','riyadh','dubai','qalubia','mohandessin',\n",
    "          'gunsberg','jeddah','dakahlia','kuwait','shorouk','helwan','of','the','mahala','khaima','suez','sheikh',\n",
    "         'beheira','benha','5th','qatar','abbassia','sokhna','ain','damanhour','mahla','17','mohandesin','mohandessein','faisal'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "v6j2I6lzZgIl",
    "outputId": "1f89e80e-98a4-4c20-e943-5c5aecbef980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1265"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(sorted_vocab))\n",
    "for word in places:\n",
    "    if word in sorted_vocab:\n",
    "        sorted_vocab.remove(word)\n",
    "len(sorted_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MB00qOSMBEDZ"
   },
   "source": [
    "# convert titles to numeric data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sj5O2m4jZgIn"
   },
   "outputs": [],
   "source": [
    "# mapping dictionary for words to integers\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(sorted_vocab, 1)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "e71ROoDrZgIp",
    "outputId": "f45508a9-ff92-4568-f55c-ff8a25619304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "developer :  1\n",
      "senior :  2\n",
      "engineer :  3\n",
      "sales :  4\n",
      "manager :  5\n",
      "specialist :  6\n",
      "software :  7\n",
      "marketing :  8\n",
      "executive :  9\n"
     ]
    }
   ],
   "source": [
    "for k,v in vocab_to_int.items():\n",
    "    if v<10:\n",
    "        print(k,': ',v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dH5VqO59ZgIr"
   },
   "outputs": [],
   "source": [
    "# mapping dictionary for integers to words\n",
    "int_to_vocab = {v: k for k, v in vocab_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "6uEuHKVmZgIu",
    "outputId": "5583c51d-0f90-4847-b15c-25741d779f7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Full', 'Stack', 'PHP', 'Developer'],\n",
       " ['CISCO', 'Collaboration', 'Specialist', 'Engineer'],\n",
       " ['Senior', 'Back', 'End', 'PHP', 'Developer'],\n",
       " ['UX', 'Designer'],\n",
       " ['Java', 'Technical', 'Lead'],\n",
       " ['Technical', 'Support', 'Engineer'],\n",
       " ['Senior', 'iOS', 'Developer'],\n",
       " ['Mechanical', 'Engineer'],\n",
       " ['Real', 'Estate', 'Sales', 'Specialist', '10th', 'of', 'Ramadan'],\n",
       " ['School', 'Principal']]"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles=[]\n",
    "for title in data['title']:\n",
    "    titles.append(re.sub(\"[^\\w]\", \" \",  title).split())\n",
    "titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CkyKrHPAZgIw"
   },
   "outputs": [],
   "source": [
    "# building a list contains job titles as integers\n",
    "titles_as_ints = titles[:]\n",
    "for j,title in enumerate(titles_as_ints):\n",
    "    for k,word in enumerate(title):\n",
    "        if word.lower() in vocab_to_int.keys():\n",
    "            titles_as_ints[j][k] = vocab_to_int[word.lower()] \n",
    "        else:\n",
    "            titles_as_ints[j][k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NnL6bHuiZgIz"
   },
   "outputs": [],
   "source": [
    "# remove '0' words (the previously cleaned words)\n",
    "for j,title in enumerate(titles_as_ints):\n",
    "    for k,word in enumerate(title):\n",
    "        if word == 0: \n",
    "            titles_as_ints[j].remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "qYi0qt0MZgI1",
    "outputId": "96d1d79a-99d2-4a19-9df4-2d333ca6afd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[25, 19, 36, 1],\n",
       " [429, 519, 6, 3],\n",
       " [2, 59, 12, 36, 1],\n",
       " [40, 10],\n",
       " [56, 13, 57],\n",
       " [13, 29, 3],\n",
       " [2, 46, 1],\n",
       " [72, 3],\n",
       " [53, 55, 4, 6, 296, 297],\n",
       " [165, 306]]"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_as_ints[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J65qQM--ZgI4"
   },
   "source": [
    "#   Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p74_GKfZZgI5"
   },
   "outputs": [],
   "source": [
    "def pad_features(titles_ints, seq_length):\n",
    "\n",
    "    features = np.zeros((len(titles_ints), seq_length), dtype=int)\n",
    "\n",
    "    for i, row in enumerate(titles_ints):\n",
    "        if len(row)<6:\n",
    "          features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "        else:\n",
    "          features[i, :] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-Vz799pZgI8"
   },
   "outputs": [],
   "source": [
    "seq_length = 6\n",
    "\n",
    "# final input array\n",
    "features = pad_features(titles_as_ints, seq_length=seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ATOImdFlZgJS"
   },
   "source": [
    "#  Extract Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "fY7FYpQ6ZgJS",
    "outputId": "7cb4f1f4-029e-49b1-c0e3-ce9ecf5a8a81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Engineering - Telecom/Technology', 'IT/Software Development']\n",
      "['Installation/Maintenance/Repair', 'IT/Software Development', 'Engineering - Telecom/Technology']\n",
      "['Engineering - Telecom/Technology', 'IT/Software Development']\n",
      "['Creative/Design/Art', 'IT/Software Development']\n",
      "['Engineering - Telecom/Technology', 'IT/Software Development']\n"
     ]
    }
   ],
   "source": [
    "for i,mystr in enumerate(data['jobFunction'][:5]):\n",
    "    print(mystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "R9uMU5agZgJU",
    "outputId": "d8e53519-4556-4af5-a19b-4fd26671ed2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering - Telecom/Technology, IT/Software Development\n",
      "Installation/Maintenance/Repair, IT/Software Development, Engineering - Telecom/Technology\n",
      "Engineering - Telecom/Technology, IT/Software Development\n",
      "Creative/Design/Art, IT/Software Development\n",
      "Engineering - Telecom/Technology, IT/Software Development\n"
     ]
    }
   ],
   "source": [
    "for i,mystr in enumerate(data['jobFunction'][:5]):\n",
    "    print(re.sub('\\'', \"\", mystr)[1:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bS3zQ2HZgJW"
   },
   "outputs": [],
   "source": [
    "# building a list contains all classes in all samples\n",
    "classes=[]\n",
    "for mystr in data['jobFunction']:\n",
    "    ccc = re.sub('\\'', \"\", mystr)[1:-1].split(', ')\n",
    "    #print(ccc)\n",
    "    for element in ccc:\n",
    "        #print(type(element))\n",
    "        classes.append(element.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "7T0yTbYpI1_J",
    "outputId": "a17fb3aa-498a-454f-b444-4a281a264141"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['engineering - telecom/technology',\n",
       " 'it/software development',\n",
       " 'installation/maintenance/repair',\n",
       " 'it/software development',\n",
       " 'engineering - telecom/technology',\n",
       " 'engineering - telecom/technology',\n",
       " 'it/software development',\n",
       " 'creative/design/art',\n",
       " 'it/software development',\n",
       " 'engineering - telecom/technology']"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6x29wTqiZgJf",
    "outputId": "301a4111-20e4-4f89-87f9-e45b5780b552"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20681"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OgdfDOJZgJi"
   },
   "outputs": [],
   "source": [
    "class_count = Counter(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "omuKzzK8ZgJo",
    "outputId": "19f90f23-4669-49f6-955f-f5c49698f798"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3886"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count['engineering - telecom/technology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LhgSc4NoZgJs"
   },
   "outputs": [],
   "source": [
    "# mapping dictionary for classes to its frequency\n",
    "class_to_count = sorted(class_count, key=class_count.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "K8WiEEkSZgJ7",
    "outputId": "e267e8ff-e219-44a1-d4d3-31c8397b2a11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a529OLUNZgJ-"
   },
   "outputs": [],
   "source": [
    "unique_classes = list(set(classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5AVFlSm7ZgJ_"
   },
   "outputs": [],
   "source": [
    "# mapping dictionary for classes to its integers\n",
    "class_to_int = {word: ii for ii, word in enumerate(sorted(unique_classes))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "6DQqxoEhJcBf",
    "outputId": "15ec0847-41c9-4e6f-adfc-e0929c57bb3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accounting/finance :  0\n",
      "administration :  1\n",
      "analyst/research :  2\n",
      "banking :  3\n",
      "business development :  4\n",
      "c-level executive/gm/director :  5\n",
      "creative/design/art :  6\n",
      "customer service/support :  7\n",
      "education/teaching :  8\n",
      "engineering - construction/civil/architecture :  9\n"
     ]
    }
   ],
   "source": [
    "for k,v in class_to_int.items():\n",
    "    if v<10:\n",
    "        print(k,': ',v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UmD0eQVZgKC"
   },
   "outputs": [],
   "source": [
    "# mapping dictionary for integers to its classes\n",
    "int_to_class = {v: k for k, v in class_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KMHRyQmWZgKK"
   },
   "outputs": [],
   "source": [
    "# final array for labels to all samples\n",
    "targets = np.zeros([len(data),len(unique_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6U12ZR6ZgKO"
   },
   "outputs": [],
   "source": [
    "for j, j_f in enumerate(data['jobFunction']):\n",
    "    row = re.sub('\\'', \"\", j_f)[1:-1].split(', ')\n",
    "    for label in row:\n",
    "        idx_to_fill = class_to_int[label.lower()]\n",
    "        targets[j][idx_to_fill] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "a3PC_vwFZgKV",
    "outputId": "21646bd2-f98e-4181-c415-b818cbb28567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senior account manager  : customer service/support, marketing/pr/advertising, "
     ]
    }
   ],
   "source": [
    "nn=888\n",
    "for word in titles_as_ints[nn]:\n",
    "    print(int_to_vocab[word], end=' ')\n",
    "print(' : ',end='')\n",
    "for i,classs in enumerate(targets[nn]):\n",
    "    if classs==1:\n",
    "        print(int_to_class[i],end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "32INWNBLZgKX"
   },
   "source": [
    "# Dataloaders and batchinng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "sJc-GaA1ZgKY",
    "outputId": "5c365393-a177-4ef7-c1e5-1f76015ca8da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(8696, 6) \n",
      "Validation set: \t(1087, 6) \n",
      "Test set: \t\t(1087, 6)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "split_idx = int(len(features)*split_frac)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = targets[:split_idx], targets[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pf7cizJjZgKa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Batching for test\n",
    "valid_loader = DataLoader(valid_data, shuffle=False, batch_size=len(valid_data))\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kyorXoszZL2p"
   },
   "source": [
    "# Training and Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ldIipEVAc4L0",
    "outputId": "40155ebf-7ac7-459a-8f76-95b210a8fa8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRclAhnbR6Me"
   },
   "outputs": [],
   "source": [
    "def train_model(num_epochs, model, trainLoader, validLoader, criterion, optimizer, saving_path):   \n",
    "   \n",
    "    min_valid_loss = np.inf\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "        running_training_loss = 0\n",
    "        running_validation_loss = 0\n",
    "        model.train()\n",
    "        for inputs, labels in trainLoader:\n",
    "            if train_on_gpu:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            logits = model(inputs.float())\n",
    "            loss = criterion(logits, labels.float())        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_training_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        for inputs, labels in validLoader:\n",
    "            if train_on_gpu:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            logits = model(inputs.float())\n",
    "            loss = criterion(logits, labels.float())        \n",
    "            running_validation_loss += loss.item()\n",
    "        train_loss = running_training_loss/len(trainLoader)\n",
    "        valid_loss = running_validation_loss/len(validLoader)\n",
    "\n",
    "        print(e,' Training loss: ',round(train_loss,6),'  validation loss: ',round(valid_loss,6))\n",
    "        if valid_loss < min_valid_loss:\n",
    "            print('validation loss decreased!...Model saved')\n",
    "            torch.save(model.state_dict(), saving_path)\n",
    "            min_valid_loss = valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KnL_c1DuaPjs"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, fbeta_score, precision_score, recall_score\n",
    "from torch import nn\n",
    "\n",
    "segmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ZdQsnvWS38M"
   },
   "outputs": [],
   "source": [
    "def test_model(model, prob_threshold, testLoader):    \n",
    "    # prop_threshold  :  propability threshold to consider a class as positive\n",
    "\n",
    "    for inputs, labels in testLoader:\n",
    "        if train_on_gpu:\n",
    "          inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        logits = model(inputs.float())\n",
    "        break\n",
    "    out = segmoid(logits) \n",
    "\n",
    "    allout = out > prob_threshold\n",
    "\n",
    "    ypred = allout.cpu().numpy().astype(np.float64)\n",
    "    ytrue = labels.cpu().numpy().astype(np.float64)\n",
    "\n",
    "    recall = recall_score(ytrue, ypred, average='weighted')\n",
    "    precesion = precision_score(ytrue, ypred, average='weighted')\n",
    "    fbeta = fbeta_score(ytrue, ypred, average='weighted',beta=1)\n",
    "\n",
    "    print('#######################\\nOVERALL SCORES:')\n",
    "    print('recall    :',round(recall,2))\n",
    "    print('precesion:',round(precesion,2))\n",
    "    print('f1_score    :',round(fbeta,2))\n",
    "    print('\\n#######################\\n')\n",
    "\n",
    "    recall_per_class     = recall_score(ytrue, ypred, average=None)\n",
    "    precesion_per_class = precision_score(ytrue, ypred, average=None)\n",
    "    fbeta_per_class     = fbeta_score(ytrue, ypred, average=None ,beta=1)\n",
    "\n",
    "    print('SCORES PER CLASS:\\n')\n",
    "    print('\\t\\t\\t\\t recal-precision-f1_score \\t no. of occurrences in dataset')\n",
    "    for i in range(len(recall_per_class)):\n",
    "      print(i,int_to_class[i], '\\n\\t\\t\\t\\t', round(recall_per_class[i],2),'\\t', round(precesion_per_class[i],2), '\\t',\n",
    "                                              round(fbeta_per_class[i],2),'\\t\\t',class_count[int_to_class[i]])\n",
    "      print('---------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WBaNj0X_DFYz"
   },
   "source": [
    "# Building first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AI7g5RBTZgKb"
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eDae11t196AW"
   },
   "outputs": [],
   "source": [
    "class neural_network1(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, output_size)\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nKvTHEEG96SM"
   },
   "outputs": [],
   "source": [
    "model1 = neural_network1( input_size=seq_length, output_size=len(unique_classes))\n",
    "if train_on_gpu:\n",
    "    model1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wfsa75um96qn"
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()  #pos_weight= loss_weights.cuda()\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wr_5Z40P96L1",
    "outputId": "0bb8529d-8086-4473-e56a-cd7cb8710f2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Training loss:  0.486782   validation loss:  0.353814\n",
      "validation loss decreased!...Model saved\n",
      "1  Training loss:  0.320124   validation loss:  0.326842\n",
      "validation loss decreased!...Model saved\n",
      "2  Training loss:  0.303012   validation loss:  0.316884\n",
      "validation loss decreased!...Model saved\n",
      "3  Training loss:  0.295442   validation loss:  0.311665\n",
      "validation loss decreased!...Model saved\n",
      "4  Training loss:  0.289881   validation loss:  0.307058\n",
      "validation loss decreased!...Model saved\n",
      "5  Training loss:  0.284721   validation loss:  0.303206\n",
      "validation loss decreased!...Model saved\n",
      "6  Training loss:  0.279125   validation loss:  0.294439\n",
      "validation loss decreased!...Model saved\n",
      "7  Training loss:  0.272804   validation loss:  0.287727\n",
      "validation loss decreased!...Model saved\n",
      "8  Training loss:  0.26507   validation loss:  0.278911\n",
      "validation loss decreased!...Model saved\n",
      "9  Training loss:  0.255193   validation loss:  0.267648\n",
      "validation loss decreased!...Model saved\n",
      "10  Training loss:  0.243541   validation loss:  0.25375\n",
      "validation loss decreased!...Model saved\n",
      "11  Training loss:  0.228438   validation loss:  0.237121\n",
      "validation loss decreased!...Model saved\n",
      "12  Training loss:  0.213192   validation loss:  0.217917\n",
      "validation loss decreased!...Model saved\n",
      "13  Training loss:  0.19767   validation loss:  0.199854\n",
      "validation loss decreased!...Model saved\n",
      "14  Training loss:  0.183738   validation loss:  0.188654\n",
      "validation loss decreased!...Model saved\n",
      "15  Training loss:  0.174173   validation loss:  0.177919\n",
      "validation loss decreased!...Model saved\n",
      "16  Training loss:  0.167076   validation loss:  0.170972\n",
      "validation loss decreased!...Model saved\n",
      "17  Training loss:  0.160949   validation loss:  0.164594\n",
      "validation loss decreased!...Model saved\n",
      "18  Training loss:  0.156715   validation loss:  0.162119\n",
      "validation loss decreased!...Model saved\n",
      "19  Training loss:  0.154337   validation loss:  0.161152\n",
      "validation loss decreased!...Model saved\n",
      "20  Training loss:  0.152337   validation loss:  0.158167\n",
      "validation loss decreased!...Model saved\n",
      "21  Training loss:  0.14961   validation loss:  0.15563\n",
      "validation loss decreased!...Model saved\n",
      "22  Training loss:  0.149021   validation loss:  0.156886\n",
      "23  Training loss:  0.147138   validation loss:  0.155152\n",
      "validation loss decreased!...Model saved\n",
      "24  Training loss:  0.146543   validation loss:  0.154028\n",
      "validation loss decreased!...Model saved\n",
      "25  Training loss:  0.145701   validation loss:  0.155985\n",
      "26  Training loss:  0.145163   validation loss:  0.153479\n",
      "validation loss decreased!...Model saved\n",
      "27  Training loss:  0.144939   validation loss:  0.153103\n",
      "validation loss decreased!...Model saved\n",
      "28  Training loss:  0.143991   validation loss:  0.151832\n",
      "validation loss decreased!...Model saved\n",
      "29  Training loss:  0.14339   validation loss:  0.148777\n",
      "validation loss decreased!...Model saved\n",
      "30  Training loss:  0.141871   validation loss:  0.152968\n",
      "31  Training loss:  0.143328   validation loss:  0.154374\n",
      "32  Training loss:  0.142249   validation loss:  0.147068\n",
      "validation loss decreased!...Model saved\n",
      "33  Training loss:  0.140889   validation loss:  0.148875\n",
      "34  Training loss:  0.140665   validation loss:  0.14691\n",
      "validation loss decreased!...Model saved\n",
      "35  Training loss:  0.139324   validation loss:  0.147838\n",
      "36  Training loss:  0.139233   validation loss:  0.150745\n",
      "37  Training loss:  0.138055   validation loss:  0.146029\n",
      "validation loss decreased!...Model saved\n",
      "38  Training loss:  0.136979   validation loss:  0.146813\n",
      "39  Training loss:  0.13703   validation loss:  0.148638\n",
      "40  Training loss:  0.136058   validation loss:  0.14429\n",
      "validation loss decreased!...Model saved\n",
      "41  Training loss:  0.136378   validation loss:  0.146467\n",
      "42  Training loss:  0.135527   validation loss:  0.142753\n",
      "validation loss decreased!...Model saved\n",
      "43  Training loss:  0.135985   validation loss:  0.141104\n",
      "validation loss decreased!...Model saved\n",
      "44  Training loss:  0.133195   validation loss:  0.140819\n",
      "validation loss decreased!...Model saved\n",
      "45  Training loss:  0.132074   validation loss:  0.140635\n",
      "validation loss decreased!...Model saved\n",
      "46  Training loss:  0.132389   validation loss:  0.13868\n",
      "validation loss decreased!...Model saved\n",
      "47  Training loss:  0.131527   validation loss:  0.138998\n",
      "48  Training loss:  0.131644   validation loss:  0.142032\n",
      "49  Training loss:  0.130203   validation loss:  0.141202\n",
      "50  Training loss:  0.130173   validation loss:  0.138092\n",
      "validation loss decreased!...Model saved\n",
      "51  Training loss:  0.128498   validation loss:  0.138718\n",
      "52  Training loss:  0.128427   validation loss:  0.137065\n",
      "validation loss decreased!...Model saved\n",
      "53  Training loss:  0.129069   validation loss:  0.136533\n",
      "validation loss decreased!...Model saved\n",
      "54  Training loss:  0.126463   validation loss:  0.135986\n",
      "validation loss decreased!...Model saved\n",
      "55  Training loss:  0.126877   validation loss:  0.134601\n",
      "validation loss decreased!...Model saved\n",
      "56  Training loss:  0.126624   validation loss:  0.135734\n",
      "57  Training loss:  0.125557   validation loss:  0.133904\n",
      "validation loss decreased!...Model saved\n",
      "58  Training loss:  0.125775   validation loss:  0.134209\n",
      "59  Training loss:  0.126278   validation loss:  0.138146\n",
      "60  Training loss:  0.125341   validation loss:  0.13307\n",
      "validation loss decreased!...Model saved\n",
      "61  Training loss:  0.122866   validation loss:  0.13216\n",
      "validation loss decreased!...Model saved\n",
      "62  Training loss:  0.12296   validation loss:  0.133568\n",
      "63  Training loss:  0.122426   validation loss:  0.132955\n",
      "64  Training loss:  0.122879   validation loss:  0.133075\n",
      "65  Training loss:  0.121803   validation loss:  0.131709\n",
      "validation loss decreased!...Model saved\n",
      "66  Training loss:  0.121511   validation loss:  0.132247\n",
      "67  Training loss:  0.120665   validation loss:  0.131649\n",
      "validation loss decreased!...Model saved\n",
      "68  Training loss:  0.120385   validation loss:  0.130873\n",
      "validation loss decreased!...Model saved\n",
      "69  Training loss:  0.120268   validation loss:  0.130858\n",
      "validation loss decreased!...Model saved\n",
      "70  Training loss:  0.120334   validation loss:  0.128828\n",
      "validation loss decreased!...Model saved\n",
      "71  Training loss:  0.119486   validation loss:  0.130735\n",
      "72  Training loss:  0.119182   validation loss:  0.128615\n",
      "validation loss decreased!...Model saved\n",
      "73  Training loss:  0.118836   validation loss:  0.13148\n",
      "74  Training loss:  0.118568   validation loss:  0.129206\n",
      "75  Training loss:  0.117459   validation loss:  0.127724\n",
      "validation loss decreased!...Model saved\n",
      "76  Training loss:  0.118213   validation loss:  0.127822\n",
      "77  Training loss:  0.117368   validation loss:  0.129081\n",
      "78  Training loss:  0.11688   validation loss:  0.126921\n",
      "validation loss decreased!...Model saved\n",
      "79  Training loss:  0.115822   validation loss:  0.129973\n",
      "80  Training loss:  0.116349   validation loss:  0.126894\n",
      "validation loss decreased!...Model saved\n",
      "81  Training loss:  0.11687   validation loss:  0.12697\n",
      "82  Training loss:  0.115797   validation loss:  0.12762\n",
      "83  Training loss:  0.116395   validation loss:  0.128116\n",
      "84  Training loss:  0.115589   validation loss:  0.12745\n",
      "85  Training loss:  0.114635   validation loss:  0.128311\n",
      "86  Training loss:  0.114878   validation loss:  0.126354\n",
      "validation loss decreased!...Model saved\n",
      "87  Training loss:  0.114688   validation loss:  0.127313\n",
      "88  Training loss:  0.113286   validation loss:  0.126872\n",
      "89  Training loss:  0.114709   validation loss:  0.125512\n",
      "validation loss decreased!...Model saved\n",
      "90  Training loss:  0.113874   validation loss:  0.12629\n",
      "91  Training loss:  0.11247   validation loss:  0.127643\n",
      "92  Training loss:  0.112954   validation loss:  0.124699\n",
      "validation loss decreased!...Model saved\n",
      "93  Training loss:  0.112857   validation loss:  0.127598\n",
      "94  Training loss:  0.111699   validation loss:  0.124322\n",
      "validation loss decreased!...Model saved\n",
      "95  Training loss:  0.112651   validation loss:  0.12564\n",
      "96  Training loss:  0.111124   validation loss:  0.125069\n",
      "97  Training loss:  0.110951   validation loss:  0.128663\n",
      "98  Training loss:  0.11092   validation loss:  0.12683\n",
      "99  Training loss:  0.110829   validation loss:  0.127037\n",
      "100  Training loss:  0.109412   validation loss:  0.12479\n",
      "101  Training loss:  0.11023   validation loss:  0.126205\n",
      "102  Training loss:  0.110244   validation loss:  0.124368\n",
      "103  Training loss:  0.109968   validation loss:  0.125977\n",
      "104  Training loss:  0.10964   validation loss:  0.123476\n",
      "validation loss decreased!...Model saved\n",
      "105  Training loss:  0.108978   validation loss:  0.123711\n",
      "106  Training loss:  0.108919   validation loss:  0.122372\n",
      "validation loss decreased!...Model saved\n",
      "107  Training loss:  0.108078   validation loss:  0.12429\n",
      "108  Training loss:  0.108642   validation loss:  0.122636\n",
      "109  Training loss:  0.107272   validation loss:  0.122829\n",
      "110  Training loss:  0.107334   validation loss:  0.122476\n",
      "111  Training loss:  0.106578   validation loss:  0.124292\n",
      "112  Training loss:  0.107794   validation loss:  0.122707\n",
      "113  Training loss:  0.107852   validation loss:  0.121066\n",
      "validation loss decreased!...Model saved\n",
      "114  Training loss:  0.10663   validation loss:  0.124214\n",
      "115  Training loss:  0.106583   validation loss:  0.1269\n",
      "116  Training loss:  0.107027   validation loss:  0.124612\n",
      "117  Training loss:  0.10635   validation loss:  0.124324\n",
      "118  Training loss:  0.10598   validation loss:  0.122241\n",
      "119  Training loss:  0.105045   validation loss:  0.119896\n",
      "validation loss decreased!...Model saved\n",
      "120  Training loss:  0.105446   validation loss:  0.122654\n",
      "121  Training loss:  0.103859   validation loss:  0.123171\n",
      "122  Training loss:  0.105635   validation loss:  0.120507\n",
      "123  Training loss:  0.103961   validation loss:  0.122196\n",
      "124  Training loss:  0.104114   validation loss:  0.122578\n",
      "125  Training loss:  0.104552   validation loss:  0.120799\n",
      "126  Training loss:  0.104833   validation loss:  0.118694\n",
      "validation loss decreased!...Model saved\n",
      "127  Training loss:  0.103443   validation loss:  0.122285\n",
      "128  Training loss:  0.102624   validation loss:  0.119888\n",
      "129  Training loss:  0.102353   validation loss:  0.121427\n",
      "130  Training loss:  0.10243   validation loss:  0.11852\n",
      "validation loss decreased!...Model saved\n",
      "131  Training loss:  0.102166   validation loss:  0.122923\n",
      "132  Training loss:  0.102801   validation loss:  0.11962\n",
      "133  Training loss:  0.102539   validation loss:  0.1205\n",
      "134  Training loss:  0.102548   validation loss:  0.122222\n",
      "135  Training loss:  0.102151   validation loss:  0.120884\n",
      "136  Training loss:  0.1017   validation loss:  0.119447\n",
      "137  Training loss:  0.101113   validation loss:  0.120803\n",
      "138  Training loss:  0.101314   validation loss:  0.120924\n",
      "139  Training loss:  0.101177   validation loss:  0.120913\n",
      "140  Training loss:  0.102016   validation loss:  0.121203\n",
      "141  Training loss:  0.101141   validation loss:  0.119362\n",
      "142  Training loss:  0.101251   validation loss:  0.119306\n",
      "143  Training loss:  0.09973   validation loss:  0.121905\n",
      "144  Training loss:  0.100551   validation loss:  0.119714\n",
      "145  Training loss:  0.099484   validation loss:  0.119108\n",
      "146  Training loss:  0.099163   validation loss:  0.121624\n",
      "147  Training loss:  0.09958   validation loss:  0.120634\n",
      "148  Training loss:  0.100609   validation loss:  0.119035\n",
      "149  Training loss:  0.099102   validation loss:  0.120975\n",
      "150  Training loss:  0.099701   validation loss:  0.120377\n",
      "151  Training loss:  0.098795   validation loss:  0.119771\n",
      "152  Training loss:  0.099022   validation loss:  0.119839\n",
      "153  Training loss:  0.099778   validation loss:  0.122353\n",
      "154  Training loss:  0.099049   validation loss:  0.118032\n",
      "validation loss decreased!...Model saved\n",
      "155  Training loss:  0.098514   validation loss:  0.118175\n",
      "156  Training loss:  0.098103   validation loss:  0.119339\n",
      "157  Training loss:  0.098351   validation loss:  0.118028\n",
      "validation loss decreased!...Model saved\n",
      "158  Training loss:  0.09844   validation loss:  0.118454\n",
      "159  Training loss:  0.09806   validation loss:  0.119056\n",
      "160  Training loss:  0.098325   validation loss:  0.120107\n",
      "161  Training loss:  0.098298   validation loss:  0.11923\n",
      "162  Training loss:  0.09757   validation loss:  0.120046\n",
      "163  Training loss:  0.097298   validation loss:  0.119255\n",
      "164  Training loss:  0.097395   validation loss:  0.118287\n",
      "165  Training loss:  0.096926   validation loss:  0.119475\n",
      "166  Training loss:  0.097617   validation loss:  0.120708\n",
      "167  Training loss:  0.0966   validation loss:  0.119384\n",
      "168  Training loss:  0.096366   validation loss:  0.119096\n",
      "169  Training loss:  0.098059   validation loss:  0.125447\n",
      "170  Training loss:  0.097563   validation loss:  0.122753\n",
      "171  Training loss:  0.096715   validation loss:  0.123387\n",
      "172  Training loss:  0.097879   validation loss:  0.122825\n",
      "173  Training loss:  0.096105   validation loss:  0.119119\n",
      "174  Training loss:  0.096198   validation loss:  0.118504\n",
      "175  Training loss:  0.096599   validation loss:  0.119297\n",
      "176  Training loss:  0.095227   validation loss:  0.118733\n",
      "177  Training loss:  0.095285   validation loss:  0.119724\n",
      "178  Training loss:  0.095562   validation loss:  0.118203\n",
      "179  Training loss:  0.095449   validation loss:  0.120597\n",
      "180  Training loss:  0.094592   validation loss:  0.11963\n",
      "181  Training loss:  0.095383   validation loss:  0.119524\n",
      "182  Training loss:  0.094439   validation loss:  0.118248\n",
      "183  Training loss:  0.095007   validation loss:  0.120776\n",
      "184  Training loss:  0.09516   validation loss:  0.118483\n",
      "185  Training loss:  0.094651   validation loss:  0.123097\n",
      "186  Training loss:  0.095178   validation loss:  0.123614\n",
      "187  Training loss:  0.094941   validation loss:  0.119777\n",
      "188  Training loss:  0.094182   validation loss:  0.117881\n",
      "validation loss decreased!...Model saved\n",
      "189  Training loss:  0.09408   validation loss:  0.119532\n",
      "190  Training loss:  0.094191   validation loss:  0.11954\n",
      "191  Training loss:  0.094511   validation loss:  0.122038\n",
      "192  Training loss:  0.094006   validation loss:  0.12008\n",
      "193  Training loss:  0.093568   validation loss:  0.123067\n",
      "194  Training loss:  0.094543   validation loss:  0.119747\n",
      "195  Training loss:  0.093896   validation loss:  0.124199\n",
      "196  Training loss:  0.093359   validation loss:  0.120279\n",
      "197  Training loss:  0.09297   validation loss:  0.118475\n",
      "198  Training loss:  0.092725   validation loss:  0.120695\n",
      "199  Training loss:  0.092624   validation loss:  0.122804\n"
     ]
    }
   ],
   "source": [
    "train_model(200, model1, train_loader, valid_loader, criterion=criterion, optimizer=optimizer1, saving_path='JobFunctionModel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "850kxcyNbl8U",
    "outputId": "50ef41f2-bb51-48de-9bb1-87675d32de7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_state_dict(torch.load('JobFunctionModel.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eDWGPWhH96I_",
    "outputId": "07b167ae-accf-46f3-e17f-afeb739caf30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################\n",
      "OVERALL SCORES:\n",
      "recall    : 0.52\n",
      "precesion: 0.64\n",
      "f1_score    : 0.53\n",
      "\n",
      "#######################\n",
      "\n",
      "SCORES PER CLASS:\n",
      "\n",
      "\t\t\t\t recal-precision-f1_score \t no. of occurrences in dataset\n",
      "0 accounting/finance \n",
      "\t\t\t\t 0.33 \t 0.73 \t 0.46 \t\t 477\n",
      "---------------------------------------------------------------------------\n",
      "1 administration \n",
      "\t\t\t\t 0.24 \t 1.0 \t 0.38 \t\t 656\n",
      "---------------------------------------------------------------------------\n",
      "2 analyst/research \n",
      "\t\t\t\t 0.39 \t 0.73 \t 0.51 \t\t 272\n",
      "---------------------------------------------------------------------------\n",
      "3 banking \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 10\n",
      "---------------------------------------------------------------------------\n",
      "4 business development \n",
      "\t\t\t\t 0.35 \t 0.64 \t 0.46 \t\t 445\n",
      "---------------------------------------------------------------------------\n",
      "5 c-level executive/gm/director \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 3\n",
      "---------------------------------------------------------------------------\n",
      "6 creative/design/art \n",
      "\t\t\t\t 0.59 \t 0.87 \t 0.7 \t\t 739\n",
      "---------------------------------------------------------------------------\n",
      "7 customer service/support \n",
      "\t\t\t\t 0.23 \t 0.68 \t 0.34 \t\t 863\n",
      "---------------------------------------------------------------------------\n",
      "8 education/teaching \n",
      "\t\t\t\t 0.21 \t 0.4 \t 0.28 \t\t 527\n",
      "---------------------------------------------------------------------------\n",
      "9 engineering - construction/civil/architecture \n",
      "\t\t\t\t 0.12 \t 0.2 \t 0.15 \t\t 302\n",
      "---------------------------------------------------------------------------\n",
      "10 engineering - mechanical/electrical \n",
      "\t\t\t\t 0.16 \t 0.36 \t 0.22 \t\t 499\n",
      "---------------------------------------------------------------------------\n",
      "11 engineering - oil & gas/energy \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 10\n",
      "---------------------------------------------------------------------------\n",
      "12 engineering - other \n",
      "\t\t\t\t 0.06 \t 0.5 \t 0.11 \t\t 169\n",
      "---------------------------------------------------------------------------\n",
      "13 engineering - telecom/technology \n",
      "\t\t\t\t 0.86 \t 0.63 \t 0.73 \t\t 3886\n",
      "---------------------------------------------------------------------------\n",
      "14 fashion \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 3\n",
      "---------------------------------------------------------------------------\n",
      "15 hospitality/hotels/food services \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 15\n",
      "---------------------------------------------------------------------------\n",
      "16 human resources \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 260\n",
      "---------------------------------------------------------------------------\n",
      "17 installation/maintenance/repair \n",
      "\t\t\t\t 0.17 \t 0.43 \t 0.24 \t\t 576\n",
      "---------------------------------------------------------------------------\n",
      "18 it/software development \n",
      "\t\t\t\t 0.87 \t 0.7 \t 0.77 \t\t 4383\n",
      "---------------------------------------------------------------------------\n",
      "19 legal \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 21\n",
      "---------------------------------------------------------------------------\n",
      "20 logistics/supply chain \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 171\n",
      "---------------------------------------------------------------------------\n",
      "21 manufacturing/production \n",
      "\t\t\t\t 0.05 \t 1.0 \t 0.09 \t\t 122\n",
      "---------------------------------------------------------------------------\n",
      "22 marketing/pr/advertising \n",
      "\t\t\t\t 0.39 \t 0.65 \t 0.49 \t\t 1400\n",
      "---------------------------------------------------------------------------\n",
      "23 media/journalism/publishing \n",
      "\t\t\t\t 0.42 \t 0.63 \t 0.5 \t\t 951\n",
      "---------------------------------------------------------------------------\n",
      "24 medical/healthcare \n",
      "\t\t\t\t 0.12 \t 0.5 \t 0.2 \t\t 217\n",
      "---------------------------------------------------------------------------\n",
      "25 nan \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 117\n",
      "---------------------------------------------------------------------------\n",
      "26 operations/management \n",
      "\t\t\t\t 0.03 \t 0.25 \t 0.06 \t\t 314\n",
      "---------------------------------------------------------------------------\n",
      "27 pharmaceutical \n",
      "\t\t\t\t 0.18 \t 1.0 \t 0.3 \t\t 129\n",
      "---------------------------------------------------------------------------\n",
      "28 project/program management \n",
      "\t\t\t\t 0.22 \t 0.55 \t 0.32 \t\t 308\n",
      "---------------------------------------------------------------------------\n",
      "29 purchasing/procurement \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 140\n",
      "---------------------------------------------------------------------------\n",
      "30 quality \n",
      "\t\t\t\t 0.11 \t 0.67 \t 0.18 \t\t 404\n",
      "---------------------------------------------------------------------------\n",
      "31 r&d/science \n",
      "\t\t\t\t 0.14 \t 0.4 \t 0.21 \t\t 119\n",
      "---------------------------------------------------------------------------\n",
      "32 sales/retail \n",
      "\t\t\t\t 0.63 \t 0.77 \t 0.69 \t\t 1802\n",
      "---------------------------------------------------------------------------\n",
      "33 sports and leisure \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 7\n",
      "---------------------------------------------------------------------------\n",
      "34 strategy/consulting \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 17\n",
      "---------------------------------------------------------------------------\n",
      "35 tourism/travel \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 10\n",
      "---------------------------------------------------------------------------\n",
      "36 training/instructor \n",
      "\t\t\t\t 0.17 \t 1.0 \t 0.29 \t\t 135\n",
      "---------------------------------------------------------------------------\n",
      "37 writing/editorial \n",
      "\t\t\t\t 0.07 \t 0.67 \t 0.13 \t\t 202\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "test_model(model1, prob_threshold= 0.35, testLoader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzQmelnxatZc"
   },
   "source": [
    "# second model (adding embedding layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btKwJuIhZgKe"
   },
   "outputs": [],
   "source": [
    "class neural_network2(nn.Module):\n",
    "    def __init__(self, input_size, vocab_size, output_size, embedding_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc1 = nn.Linear(input_size*embedding_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, output_size)\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x.long())\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "30MJTq4fZgKf"
   },
   "outputs": [],
   "source": [
    "embed_dim = 400\n",
    "model2 = neural_network2( input_size=seq_length,vocab_size=len(vocab_to_int), output_size=len(unique_classes), embedding_dim=embed_dim)\n",
    "if train_on_gpu:\n",
    "    model2.cuda()\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9dXnGGrbb1cD",
    "outputId": "ecbb873b-54ab-488c-e82c-f55c853d55f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Training loss:  0.25288   validation loss:  0.128546\n",
      "validation loss decreased!...Model saved\n",
      "1  Training loss:  0.110384   validation loss:  0.098358\n",
      "validation loss decreased!...Model saved\n",
      "2  Training loss:  0.087073   validation loss:  0.08274\n",
      "validation loss decreased!...Model saved\n",
      "3  Training loss:  0.073421   validation loss:  0.073646\n",
      "validation loss decreased!...Model saved\n",
      "4  Training loss:  0.064119   validation loss:  0.066339\n",
      "validation loss decreased!...Model saved\n",
      "5  Training loss:  0.057229   validation loss:  0.061372\n",
      "validation loss decreased!...Model saved\n",
      "6  Training loss:  0.05189   validation loss:  0.057932\n",
      "validation loss decreased!...Model saved\n",
      "7  Training loss:  0.047672   validation loss:  0.054904\n",
      "validation loss decreased!...Model saved\n",
      "8  Training loss:  0.043919   validation loss:  0.052144\n",
      "validation loss decreased!...Model saved\n",
      "9  Training loss:  0.040473   validation loss:  0.051356\n",
      "validation loss decreased!...Model saved\n",
      "10  Training loss:  0.037654   validation loss:  0.04858\n",
      "validation loss decreased!...Model saved\n",
      "11  Training loss:  0.035235   validation loss:  0.04795\n",
      "validation loss decreased!...Model saved\n",
      "12  Training loss:  0.032984   validation loss:  0.045397\n",
      "validation loss decreased!...Model saved\n",
      "13  Training loss:  0.031316   validation loss:  0.044951\n",
      "validation loss decreased!...Model saved\n",
      "14  Training loss:  0.029683   validation loss:  0.044217\n",
      "validation loss decreased!...Model saved\n",
      "15  Training loss:  0.02829   validation loss:  0.043372\n",
      "validation loss decreased!...Model saved\n",
      "16  Training loss:  0.026835   validation loss:  0.042812\n",
      "validation loss decreased!...Model saved\n",
      "17  Training loss:  0.025732   validation loss:  0.042267\n",
      "validation loss decreased!...Model saved\n",
      "18  Training loss:  0.024667   validation loss:  0.041268\n",
      "validation loss decreased!...Model saved\n",
      "19  Training loss:  0.023834   validation loss:  0.041402\n",
      "20  Training loss:  0.02302   validation loss:  0.0411\n",
      "validation loss decreased!...Model saved\n",
      "21  Training loss:  0.022491   validation loss:  0.040986\n",
      "validation loss decreased!...Model saved\n",
      "22  Training loss:  0.021566   validation loss:  0.040493\n",
      "validation loss decreased!...Model saved\n",
      "23  Training loss:  0.021118   validation loss:  0.040545\n",
      "24  Training loss:  0.020426   validation loss:  0.04073\n",
      "25  Training loss:  0.020103   validation loss:  0.03983\n",
      "validation loss decreased!...Model saved\n",
      "26  Training loss:  0.019647   validation loss:  0.040186\n",
      "27  Training loss:  0.01929   validation loss:  0.039998\n",
      "28  Training loss:  0.018906   validation loss:  0.040188\n",
      "29  Training loss:  0.018457   validation loss:  0.040797\n",
      "30  Training loss:  0.018459   validation loss:  0.043041\n",
      "31  Training loss:  0.017858   validation loss:  0.040219\n",
      "32  Training loss:  0.017635   validation loss:  0.040824\n",
      "33  Training loss:  0.017478   validation loss:  0.040805\n",
      "34  Training loss:  0.017098   validation loss:  0.041794\n",
      "35  Training loss:  0.016955   validation loss:  0.042132\n",
      "36  Training loss:  0.016874   validation loss:  0.040895\n",
      "37  Training loss:  0.016658   validation loss:  0.040392\n",
      "38  Training loss:  0.0163   validation loss:  0.04195\n",
      "39  Training loss:  0.016253   validation loss:  0.041394\n",
      "40  Training loss:  0.016264   validation loss:  0.041178\n",
      "41  Training loss:  0.016251   validation loss:  0.042174\n",
      "42  Training loss:  0.015961   validation loss:  0.042743\n",
      "43  Training loss:  0.015813   validation loss:  0.041254\n",
      "44  Training loss:  0.015715   validation loss:  0.043269\n",
      "45  Training loss:  0.015574   validation loss:  0.041813\n",
      "46  Training loss:  0.015583   validation loss:  0.041635\n",
      "47  Training loss:  0.015442   validation loss:  0.042372\n",
      "48  Training loss:  0.015071   validation loss:  0.041294\n",
      "49  Training loss:  0.015282   validation loss:  0.04158\n",
      "50  Training loss:  0.015126   validation loss:  0.043194\n",
      "51  Training loss:  0.015092   validation loss:  0.042134\n",
      "52  Training loss:  0.015054   validation loss:  0.042861\n",
      "53  Training loss:  0.014857   validation loss:  0.042376\n",
      "54  Training loss:  0.014935   validation loss:  0.043348\n",
      "55  Training loss:  0.01477   validation loss:  0.041658\n",
      "56  Training loss:  0.014765   validation loss:  0.042734\n",
      "57  Training loss:  0.014677   validation loss:  0.043038\n",
      "58  Training loss:  0.014503   validation loss:  0.04349\n",
      "59  Training loss:  0.014725   validation loss:  0.042492\n",
      "60  Training loss:  0.01464   validation loss:  0.043189\n",
      "61  Training loss:  0.014582   validation loss:  0.043179\n",
      "62  Training loss:  0.014614   validation loss:  0.043968\n",
      "63  Training loss:  0.014349   validation loss:  0.042776\n",
      "64  Training loss:  0.014369   validation loss:  0.044184\n",
      "65  Training loss:  0.014521   validation loss:  0.043817\n",
      "66  Training loss:  0.014319   validation loss:  0.044108\n",
      "67  Training loss:  0.014508   validation loss:  0.042733\n",
      "68  Training loss:  0.014265   validation loss:  0.043942\n",
      "69  Training loss:  0.014255   validation loss:  0.043958\n",
      "70  Training loss:  0.014137   validation loss:  0.044368\n",
      "71  Training loss:  0.014293   validation loss:  0.044422\n",
      "72  Training loss:  0.01413   validation loss:  0.043291\n",
      "73  Training loss:  0.014147   validation loss:  0.043733\n",
      "74  Training loss:  0.014012   validation loss:  0.044934\n",
      "75  Training loss:  0.014347   validation loss:  0.043573\n",
      "76  Training loss:  0.014102   validation loss:  0.044869\n",
      "77  Training loss:  0.013924   validation loss:  0.044141\n",
      "78  Training loss:  0.014175   validation loss:  0.044218\n",
      "79  Training loss:  0.013948   validation loss:  0.045029\n",
      "80  Training loss:  0.013941   validation loss:  0.045274\n",
      "81  Training loss:  0.013926   validation loss:  0.045334\n",
      "82  Training loss:  0.014049   validation loss:  0.044137\n",
      "83  Training loss:  0.013723   validation loss:  0.045069\n",
      "84  Training loss:  0.01393   validation loss:  0.043837\n",
      "85  Training loss:  0.013792   validation loss:  0.045364\n",
      "86  Training loss:  0.0139   validation loss:  0.044112\n",
      "87  Training loss:  0.013892   validation loss:  0.044617\n",
      "88  Training loss:  0.013819   validation loss:  0.044336\n",
      "89  Training loss:  0.013748   validation loss:  0.044908\n",
      "90  Training loss:  0.013784   validation loss:  0.04421\n",
      "91  Training loss:  0.013958   validation loss:  0.044601\n",
      "92  Training loss:  0.013855   validation loss:  0.044967\n",
      "93  Training loss:  0.013681   validation loss:  0.04404\n",
      "94  Training loss:  0.013693   validation loss:  0.045026\n",
      "95  Training loss:  0.013704   validation loss:  0.045359\n",
      "96  Training loss:  0.013629   validation loss:  0.044988\n",
      "97  Training loss:  0.01375   validation loss:  0.044618\n",
      "98  Training loss:  0.013747   validation loss:  0.045252\n",
      "99  Training loss:  0.013673   validation loss:  0.045713\n",
      "100  Training loss:  0.013645   validation loss:  0.045943\n",
      "101  Training loss:  0.013681   validation loss:  0.044561\n",
      "102  Training loss:  0.01374   validation loss:  0.044055\n",
      "103  Training loss:  0.01368   validation loss:  0.044544\n",
      "104  Training loss:  0.013513   validation loss:  0.045695\n",
      "105  Training loss:  0.013592   validation loss:  0.045722\n",
      "106  Training loss:  0.013669   validation loss:  0.04566\n",
      "107  Training loss:  0.013621   validation loss:  0.046039\n",
      "108  Training loss:  0.013581   validation loss:  0.04658\n",
      "109  Training loss:  0.013632   validation loss:  0.045668\n",
      "110  Training loss:  0.01355   validation loss:  0.045297\n",
      "111  Training loss:  0.013356   validation loss:  0.045868\n",
      "112  Training loss:  0.013457   validation loss:  0.045562\n",
      "113  Training loss:  0.013594   validation loss:  0.04545\n",
      "114  Training loss:  0.013478   validation loss:  0.044774\n",
      "115  Training loss:  0.013477   validation loss:  0.044923\n",
      "116  Training loss:  0.013421   validation loss:  0.045895\n",
      "117  Training loss:  0.013468   validation loss:  0.045958\n",
      "118  Training loss:  0.013443   validation loss:  0.044953\n",
      "119  Training loss:  0.013369   validation loss:  0.045253\n",
      "120  Training loss:  0.013398   validation loss:  0.045004\n",
      "121  Training loss:  0.013448   validation loss:  0.045097\n",
      "122  Training loss:  0.01338   validation loss:  0.044734\n",
      "123  Training loss:  0.013275   validation loss:  0.044932\n",
      "124  Training loss:  0.013515   validation loss:  0.045928\n",
      "125  Training loss:  0.013379   validation loss:  0.044506\n",
      "126  Training loss:  0.013386   validation loss:  0.044662\n",
      "127  Training loss:  0.013373   validation loss:  0.045063\n",
      "128  Training loss:  0.013282   validation loss:  0.045366\n",
      "129  Training loss:  0.013346   validation loss:  0.046478\n",
      "130  Training loss:  0.013374   validation loss:  0.046381\n",
      "131  Training loss:  0.01318   validation loss:  0.045795\n",
      "132  Training loss:  0.013239   validation loss:  0.046094\n",
      "133  Training loss:  0.013302   validation loss:  0.04616\n",
      "134  Training loss:  0.013337   validation loss:  0.044928\n",
      "135  Training loss:  0.013389   validation loss:  0.045228\n",
      "136  Training loss:  0.013256   validation loss:  0.046716\n",
      "137  Training loss:  0.013237   validation loss:  0.044729\n",
      "138  Training loss:  0.013139   validation loss:  0.045099\n",
      "139  Training loss:  0.01326   validation loss:  0.045136\n",
      "140  Training loss:  0.013266   validation loss:  0.045914\n",
      "141  Training loss:  0.01325   validation loss:  0.045247\n",
      "142  Training loss:  0.013197   validation loss:  0.046774\n",
      "143  Training loss:  0.013278   validation loss:  0.045632\n",
      "144  Training loss:  0.013241   validation loss:  0.044929\n",
      "145  Training loss:  0.013217   validation loss:  0.04512\n",
      "146  Training loss:  0.013295   validation loss:  0.045881\n",
      "147  Training loss:  0.013165   validation loss:  0.045645\n",
      "148  Training loss:  0.013164   validation loss:  0.046127\n",
      "149  Training loss:  0.013292   validation loss:  0.046583\n",
      "150  Training loss:  0.013092   validation loss:  0.045986\n",
      "151  Training loss:  0.01312   validation loss:  0.046113\n",
      "152  Training loss:  0.013099   validation loss:  0.046447\n",
      "153  Training loss:  0.013267   validation loss:  0.044849\n",
      "154  Training loss:  0.013221   validation loss:  0.045271\n",
      "155  Training loss:  0.013112   validation loss:  0.04583\n",
      "156  Training loss:  0.013219   validation loss:  0.044723\n",
      "157  Training loss:  0.013087   validation loss:  0.044965\n",
      "158  Training loss:  0.013117   validation loss:  0.045328\n",
      "159  Training loss:  0.013133   validation loss:  0.045409\n",
      "160  Training loss:  0.013065   validation loss:  0.045833\n",
      "161  Training loss:  0.013067   validation loss:  0.045394\n",
      "162  Training loss:  0.013192   validation loss:  0.045213\n",
      "163  Training loss:  0.013073   validation loss:  0.04584\n",
      "164  Training loss:  0.012991   validation loss:  0.045991\n",
      "165  Training loss:  0.013022   validation loss:  0.04533\n",
      "166  Training loss:  0.013102   validation loss:  0.04581\n",
      "167  Training loss:  0.013033   validation loss:  0.046387\n",
      "168  Training loss:  0.013167   validation loss:  0.046782\n",
      "169  Training loss:  0.013045   validation loss:  0.045049\n",
      "170  Training loss:  0.01295   validation loss:  0.04667\n",
      "171  Training loss:  0.013068   validation loss:  0.04686\n",
      "172  Training loss:  0.013011   validation loss:  0.045455\n",
      "173  Training loss:  0.0131   validation loss:  0.04632\n",
      "174  Training loss:  0.013071   validation loss:  0.04578\n",
      "175  Training loss:  0.012954   validation loss:  0.045292\n",
      "176  Training loss:  0.012991   validation loss:  0.046114\n",
      "177  Training loss:  0.012989   validation loss:  0.047995\n",
      "178  Training loss:  0.01295   validation loss:  0.046793\n",
      "179  Training loss:  0.012967   validation loss:  0.04618\n",
      "180  Training loss:  0.013021   validation loss:  0.046005\n",
      "181  Training loss:  0.012837   validation loss:  0.045737\n",
      "182  Training loss:  0.012943   validation loss:  0.046692\n",
      "183  Training loss:  0.012969   validation loss:  0.0462\n",
      "184  Training loss:  0.013036   validation loss:  0.045764\n",
      "185  Training loss:  0.012911   validation loss:  0.045714\n",
      "186  Training loss:  0.012819   validation loss:  0.046016\n",
      "187  Training loss:  0.012994   validation loss:  0.046165\n",
      "188  Training loss:  0.01302   validation loss:  0.046472\n",
      "189  Training loss:  0.012868   validation loss:  0.046322\n",
      "190  Training loss:  0.01311   validation loss:  0.046608\n",
      "191  Training loss:  0.012959   validation loss:  0.046638\n",
      "192  Training loss:  0.012887   validation loss:  0.045792\n",
      "193  Training loss:  0.01281   validation loss:  0.046442\n",
      "194  Training loss:  0.012971   validation loss:  0.046136\n",
      "195  Training loss:  0.012876   validation loss:  0.045949\n",
      "196  Training loss:  0.01303   validation loss:  0.046251\n",
      "197  Training loss:  0.012902   validation loss:  0.047651\n",
      "198  Training loss:  0.013025   validation loss:  0.046818\n",
      "199  Training loss:  0.013099   validation loss:  0.04635\n"
     ]
    }
   ],
   "source": [
    "train_model(200, model2, train_loader, valid_loader, criterion=criterion, optimizer=optimizer2, saving_path='JobFunctionModel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Q_pJH2WmZgK1",
    "outputId": "5e1b9bee-6b6d-4a84-aad4-395f4b863164"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load('JobFunctionModel.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2eDGlAe-N9ib",
    "outputId": "13e8c6bb-20f7-43ca-b7e3-8621a4f111cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################\n",
      "OVERALL SCORES:\n",
      "recall    : 0.88\n",
      "precesion: 0.89\n",
      "f1_score    : 0.88\n",
      "\n",
      "#######################\n",
      "\n",
      "SCORES PER CLASS:\n",
      "\n",
      "\t\t\t\t recal-precision-f1_score \t no. of occurrences in dataset\n",
      "0 accounting/finance \n",
      "\t\t\t\t 0.94 \t 0.94 \t 0.94 \t\t 477\n",
      "---------------------------------------------------------------------------\n",
      "1 administration \n",
      "\t\t\t\t 0.85 \t 0.87 \t 0.86 \t\t 656\n",
      "---------------------------------------------------------------------------\n",
      "2 analyst/research \n",
      "\t\t\t\t 0.86 \t 1.0 \t 0.92 \t\t 272\n",
      "---------------------------------------------------------------------------\n",
      "3 banking \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 10\n",
      "---------------------------------------------------------------------------\n",
      "4 business development \n",
      "\t\t\t\t 0.88 \t 0.71 \t 0.79 \t\t 445\n",
      "---------------------------------------------------------------------------\n",
      "5 c-level executive/gm/director \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 3\n",
      "---------------------------------------------------------------------------\n",
      "6 creative/design/art \n",
      "\t\t\t\t 0.87 \t 0.97 \t 0.92 \t\t 739\n",
      "---------------------------------------------------------------------------\n",
      "7 customer service/support \n",
      "\t\t\t\t 0.73 \t 0.77 \t 0.75 \t\t 863\n",
      "---------------------------------------------------------------------------\n",
      "8 education/teaching \n",
      "\t\t\t\t 0.94 \t 1.0 \t 0.97 \t\t 527\n",
      "---------------------------------------------------------------------------\n",
      "9 engineering - construction/civil/architecture \n",
      "\t\t\t\t 0.71 \t 0.75 \t 0.73 \t\t 302\n",
      "---------------------------------------------------------------------------\n",
      "10 engineering - mechanical/electrical \n",
      "\t\t\t\t 0.67 \t 0.79 \t 0.72 \t\t 499\n",
      "---------------------------------------------------------------------------\n",
      "11 engineering - oil & gas/energy \n",
      "\t\t\t\t 0.5 \t 1.0 \t 0.67 \t\t 10\n",
      "---------------------------------------------------------------------------\n",
      "12 engineering - other \n",
      "\t\t\t\t 0.19 \t 1.0 \t 0.32 \t\t 169\n",
      "---------------------------------------------------------------------------\n",
      "13 engineering - telecom/technology \n",
      "\t\t\t\t 0.95 \t 0.9 \t 0.92 \t\t 3886\n",
      "---------------------------------------------------------------------------\n",
      "14 fashion \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 3\n",
      "---------------------------------------------------------------------------\n",
      "15 hospitality/hotels/food services \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 15\n",
      "---------------------------------------------------------------------------\n",
      "16 human resources \n",
      "\t\t\t\t 0.95 \t 0.95 \t 0.95 \t\t 260\n",
      "---------------------------------------------------------------------------\n",
      "17 installation/maintenance/repair \n",
      "\t\t\t\t 0.89 \t 0.75 \t 0.81 \t\t 576\n",
      "---------------------------------------------------------------------------\n",
      "18 it/software development \n",
      "\t\t\t\t 0.95 \t 0.96 \t 0.96 \t\t 4383\n",
      "---------------------------------------------------------------------------\n",
      "19 legal \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 21\n",
      "---------------------------------------------------------------------------\n",
      "20 logistics/supply chain \n",
      "\t\t\t\t 0.92 \t 0.86 \t 0.89 \t\t 171\n",
      "---------------------------------------------------------------------------\n",
      "21 manufacturing/production \n",
      "\t\t\t\t 0.81 \t 1.0 \t 0.89 \t\t 122\n",
      "---------------------------------------------------------------------------\n",
      "22 marketing/pr/advertising \n",
      "\t\t\t\t 0.91 \t 0.87 \t 0.89 \t\t 1400\n",
      "---------------------------------------------------------------------------\n",
      "23 media/journalism/publishing \n",
      "\t\t\t\t 0.93 \t 0.86 \t 0.9 \t\t 951\n",
      "---------------------------------------------------------------------------\n",
      "24 medical/healthcare \n",
      "\t\t\t\t 0.66 \t 0.91 \t 0.76 \t\t 217\n",
      "---------------------------------------------------------------------------\n",
      "25 nan \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 117\n",
      "---------------------------------------------------------------------------\n",
      "26 operations/management \n",
      "\t\t\t\t 0.57 \t 0.59 \t 0.58 \t\t 314\n",
      "---------------------------------------------------------------------------\n",
      "27 pharmaceutical \n",
      "\t\t\t\t 0.71 \t 0.8 \t 0.75 \t\t 129\n",
      "---------------------------------------------------------------------------\n",
      "28 project/program management \n",
      "\t\t\t\t 0.93 \t 0.86 \t 0.89 \t\t 308\n",
      "---------------------------------------------------------------------------\n",
      "29 purchasing/procurement \n",
      "\t\t\t\t 0.75 \t 0.9 \t 0.82 \t\t 140\n",
      "---------------------------------------------------------------------------\n",
      "30 quality \n",
      "\t\t\t\t 0.97 \t 0.97 \t 0.97 \t\t 404\n",
      "---------------------------------------------------------------------------\n",
      "31 r&d/science \n",
      "\t\t\t\t 0.64 \t 1.0 \t 0.78 \t\t 119\n",
      "---------------------------------------------------------------------------\n",
      "32 sales/retail \n",
      "\t\t\t\t 0.97 \t 0.96 \t 0.96 \t\t 1802\n",
      "---------------------------------------------------------------------------\n",
      "33 sports and leisure \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 7\n",
      "---------------------------------------------------------------------------\n",
      "34 strategy/consulting \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 17\n",
      "---------------------------------------------------------------------------\n",
      "35 tourism/travel \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 10\n",
      "---------------------------------------------------------------------------\n",
      "36 training/instructor \n",
      "\t\t\t\t 0.67 \t 0.67 \t 0.67 \t\t 135\n",
      "---------------------------------------------------------------------------\n",
      "37 writing/editorial \n",
      "\t\t\t\t 0.81 \t 0.96 \t 0.88 \t\t 202\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "test_model(model2, prob_threshold= 0.35, testLoader = test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N2bDPfLFcLSh"
   },
   "source": [
    "# 3rd model (adding dropout and incrasing layers dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CqQxoPL5ZgNB"
   },
   "outputs": [],
   "source": [
    "class neural_network3(nn.Module):\n",
    "    def __init__(self, input_size, vocab_size, output_size, embedding_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc1 = nn.Linear(input_size*embedding_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, output_size)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x.long())\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "embed_dim = 400\n",
    "model3 = neural_network3( input_size=seq_length,vocab_size=len(vocab_to_int), output_size=len(unique_classes), embedding_dim=embed_dim)\n",
    "if train_on_gpu:\n",
    "    model3.cuda()\n",
    "\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "C9rdSGG4NBHe",
    "outputId": "eb406078-3f62-4c89-8f6a-3cd5a84e0214"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_network3(\n",
       "  (embedding): Embedding(1265, 400)\n",
       "  (fc1): Linear(in_features=2400, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc4): Linear(in_features=512, out_features=38, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lXVbk5NZX7Lc",
    "outputId": "e3a48457-fca6-461c-c85d-6dc1c4e51e85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Training loss:  0.214492   validation loss:  0.118877\n",
      "validation loss decreased!...Model saved\n",
      "1  Training loss:  0.104317   validation loss:  0.089178\n",
      "validation loss decreased!...Model saved\n",
      "2  Training loss:  0.080387   validation loss:  0.073103\n",
      "validation loss decreased!...Model saved\n",
      "3  Training loss:  0.066725   validation loss:  0.063754\n",
      "validation loss decreased!...Model saved\n",
      "4  Training loss:  0.057995   validation loss:  0.058275\n",
      "validation loss decreased!...Model saved\n",
      "5  Training loss:  0.051915   validation loss:  0.053571\n",
      "validation loss decreased!...Model saved\n",
      "6  Training loss:  0.047165   validation loss:  0.051078\n",
      "validation loss decreased!...Model saved\n",
      "7  Training loss:  0.043381   validation loss:  0.048745\n",
      "validation loss decreased!...Model saved\n",
      "8  Training loss:  0.040223   validation loss:  0.04643\n",
      "validation loss decreased!...Model saved\n",
      "9  Training loss:  0.037587   validation loss:  0.045311\n",
      "validation loss decreased!...Model saved\n",
      "10  Training loss:  0.035087   validation loss:  0.044363\n",
      "validation loss decreased!...Model saved\n",
      "11  Training loss:  0.033149   validation loss:  0.042337\n",
      "validation loss decreased!...Model saved\n",
      "12  Training loss:  0.03119   validation loss:  0.042394\n",
      "13  Training loss:  0.029727   validation loss:  0.042005\n",
      "validation loss decreased!...Model saved\n",
      "14  Training loss:  0.028378   validation loss:  0.040767\n",
      "validation loss decreased!...Model saved\n",
      "15  Training loss:  0.027575   validation loss:  0.040738\n",
      "validation loss decreased!...Model saved\n",
      "16  Training loss:  0.026388   validation loss:  0.03938\n",
      "validation loss decreased!...Model saved\n",
      "17  Training loss:  0.02515   validation loss:  0.040298\n",
      "18  Training loss:  0.024606   validation loss:  0.039791\n",
      "19  Training loss:  0.023941   validation loss:  0.039422\n",
      "20  Training loss:  0.023224   validation loss:  0.038583\n",
      "validation loss decreased!...Model saved\n",
      "21  Training loss:  0.022779   validation loss:  0.03851\n",
      "validation loss decreased!...Model saved\n",
      "22  Training loss:  0.022159   validation loss:  0.039326\n",
      "23  Training loss:  0.021664   validation loss:  0.039079\n",
      "24  Training loss:  0.021224   validation loss:  0.038819\n",
      "25  Training loss:  0.020841   validation loss:  0.038312\n",
      "validation loss decreased!...Model saved\n",
      "26  Training loss:  0.020226   validation loss:  0.03893\n",
      "27  Training loss:  0.020073   validation loss:  0.039471\n",
      "28  Training loss:  0.020019   validation loss:  0.039133\n",
      "29  Training loss:  0.019497   validation loss:  0.040035\n",
      "30  Training loss:  0.019385   validation loss:  0.03883\n",
      "31  Training loss:  0.019111   validation loss:  0.038993\n",
      "32  Training loss:  0.018519   validation loss:  0.040395\n",
      "33  Training loss:  0.01844   validation loss:  0.039628\n",
      "34  Training loss:  0.018172   validation loss:  0.039739\n",
      "35  Training loss:  0.018239   validation loss:  0.040667\n",
      "36  Training loss:  0.018163   validation loss:  0.039986\n",
      "37  Training loss:  0.018319   validation loss:  0.040449\n",
      "38  Training loss:  0.017523   validation loss:  0.039888\n",
      "39  Training loss:  0.017652   validation loss:  0.041736\n",
      "40  Training loss:  0.017357   validation loss:  0.040557\n",
      "41  Training loss:  0.017364   validation loss:  0.041287\n",
      "42  Training loss:  0.017129   validation loss:  0.040523\n",
      "43  Training loss:  0.01705   validation loss:  0.04175\n",
      "44  Training loss:  0.016667   validation loss:  0.041843\n",
      "45  Training loss:  0.016784   validation loss:  0.042052\n",
      "46  Training loss:  0.016819   validation loss:  0.042885\n",
      "47  Training loss:  0.016381   validation loss:  0.042473\n",
      "48  Training loss:  0.016618   validation loss:  0.041828\n",
      "49  Training loss:  0.016379   validation loss:  0.042002\n",
      "50  Training loss:  0.016416   validation loss:  0.042069\n",
      "51  Training loss:  0.016469   validation loss:  0.042478\n",
      "52  Training loss:  0.016205   validation loss:  0.043227\n",
      "53  Training loss:  0.016073   validation loss:  0.042893\n",
      "54  Training loss:  0.016089   validation loss:  0.043032\n",
      "55  Training loss:  0.015878   validation loss:  0.043152\n",
      "56  Training loss:  0.01578   validation loss:  0.042311\n",
      "57  Training loss:  0.015816   validation loss:  0.043869\n",
      "58  Training loss:  0.01581   validation loss:  0.043118\n",
      "59  Training loss:  0.015396   validation loss:  0.043122\n",
      "60  Training loss:  0.015604   validation loss:  0.043216\n",
      "61  Training loss:  0.01563   validation loss:  0.044224\n",
      "62  Training loss:  0.015358   validation loss:  0.044251\n",
      "63  Training loss:  0.015428   validation loss:  0.043585\n",
      "64  Training loss:  0.015498   validation loss:  0.043844\n",
      "65  Training loss:  0.015534   validation loss:  0.043845\n",
      "66  Training loss:  0.015412   validation loss:  0.043424\n",
      "67  Training loss:  0.015055   validation loss:  0.044248\n",
      "68  Training loss:  0.015279   validation loss:  0.043907\n",
      "69  Training loss:  0.015225   validation loss:  0.043505\n",
      "70  Training loss:  0.01525   validation loss:  0.044654\n",
      "71  Training loss:  0.015225   validation loss:  0.043779\n",
      "72  Training loss:  0.014889   validation loss:  0.042862\n",
      "73  Training loss:  0.015073   validation loss:  0.04368\n",
      "74  Training loss:  0.014776   validation loss:  0.044009\n",
      "75  Training loss:  0.014802   validation loss:  0.045083\n",
      "76  Training loss:  0.014664   validation loss:  0.045658\n",
      "77  Training loss:  0.014895   validation loss:  0.044215\n",
      "78  Training loss:  0.014654   validation loss:  0.044023\n",
      "79  Training loss:  0.014692   validation loss:  0.045655\n",
      "80  Training loss:  0.014607   validation loss:  0.045402\n",
      "81  Training loss:  0.01464   validation loss:  0.046079\n",
      "82  Training loss:  0.014759   validation loss:  0.045564\n",
      "83  Training loss:  0.014746   validation loss:  0.045629\n",
      "84  Training loss:  0.014444   validation loss:  0.046778\n",
      "85  Training loss:  0.014548   validation loss:  0.045551\n",
      "86  Training loss:  0.014478   validation loss:  0.046368\n",
      "87  Training loss:  0.014449   validation loss:  0.047572\n",
      "88  Training loss:  0.014353   validation loss:  0.046148\n",
      "89  Training loss:  0.014525   validation loss:  0.046091\n",
      "90  Training loss:  0.014523   validation loss:  0.046032\n",
      "91  Training loss:  0.014455   validation loss:  0.046558\n",
      "92  Training loss:  0.014173   validation loss:  0.047768\n",
      "93  Training loss:  0.014335   validation loss:  0.046829\n",
      "94  Training loss:  0.014229   validation loss:  0.047695\n",
      "95  Training loss:  0.014175   validation loss:  0.047998\n",
      "96  Training loss:  0.014064   validation loss:  0.047655\n",
      "97  Training loss:  0.014252   validation loss:  0.047904\n",
      "98  Training loss:  0.014133   validation loss:  0.047509\n",
      "99  Training loss:  0.014036   validation loss:  0.047484\n",
      "100  Training loss:  0.014131   validation loss:  0.048094\n",
      "101  Training loss:  0.014034   validation loss:  0.047763\n",
      "102  Training loss:  0.013957   validation loss:  0.04864\n",
      "103  Training loss:  0.01395   validation loss:  0.048389\n",
      "104  Training loss:  0.014055   validation loss:  0.049319\n",
      "105  Training loss:  0.01399   validation loss:  0.048143\n",
      "106  Training loss:  0.014027   validation loss:  0.049265\n",
      "107  Training loss:  0.014042   validation loss:  0.0483\n",
      "108  Training loss:  0.013859   validation loss:  0.048626\n",
      "109  Training loss:  0.013801   validation loss:  0.04958\n",
      "110  Training loss:  0.013859   validation loss:  0.048986\n",
      "111  Training loss:  0.013823   validation loss:  0.050731\n",
      "112  Training loss:  0.013846   validation loss:  0.050482\n",
      "113  Training loss:  0.013833   validation loss:  0.049429\n",
      "114  Training loss:  0.013763   validation loss:  0.04864\n",
      "115  Training loss:  0.01362   validation loss:  0.048785\n",
      "116  Training loss:  0.013824   validation loss:  0.049091\n",
      "117  Training loss:  0.013721   validation loss:  0.051761\n",
      "118  Training loss:  0.013622   validation loss:  0.050195\n",
      "119  Training loss:  0.013682   validation loss:  0.050038\n",
      "120  Training loss:  0.01357   validation loss:  0.049858\n",
      "121  Training loss:  0.013514   validation loss:  0.050178\n",
      "122  Training loss:  0.013597   validation loss:  0.050214\n",
      "123  Training loss:  0.013685   validation loss:  0.050504\n",
      "124  Training loss:  0.013535   validation loss:  0.051202\n",
      "125  Training loss:  0.013547   validation loss:  0.052549\n",
      "126  Training loss:  0.013546   validation loss:  0.052047\n",
      "127  Training loss:  0.01364   validation loss:  0.051365\n",
      "128  Training loss:  0.013521   validation loss:  0.051853\n",
      "129  Training loss:  0.013327   validation loss:  0.050985\n",
      "130  Training loss:  0.01335   validation loss:  0.052068\n",
      "131  Training loss:  0.013612   validation loss:  0.05223\n",
      "132  Training loss:  0.013468   validation loss:  0.052152\n",
      "133  Training loss:  0.013522   validation loss:  0.052266\n",
      "134  Training loss:  0.0135   validation loss:  0.052328\n",
      "135  Training loss:  0.013302   validation loss:  0.052604\n",
      "136  Training loss:  0.013551   validation loss:  0.052209\n",
      "137  Training loss:  0.013335   validation loss:  0.052342\n",
      "138  Training loss:  0.013374   validation loss:  0.052295\n",
      "139  Training loss:  0.013313   validation loss:  0.052546\n",
      "140  Training loss:  0.013368   validation loss:  0.051371\n",
      "141  Training loss:  0.013355   validation loss:  0.052286\n",
      "142  Training loss:  0.0133   validation loss:  0.051943\n",
      "143  Training loss:  0.01324   validation loss:  0.052307\n",
      "144  Training loss:  0.013273   validation loss:  0.052761\n",
      "145  Training loss:  0.013186   validation loss:  0.054863\n",
      "146  Training loss:  0.013208   validation loss:  0.052049\n",
      "147  Training loss:  0.013235   validation loss:  0.053402\n",
      "148  Training loss:  0.013123   validation loss:  0.054335\n",
      "149  Training loss:  0.013204   validation loss:  0.054165\n"
     ]
    }
   ],
   "source": [
    "train_model(150, model3, train_loader, valid_loader, criterion=criterion, optimizer=optimizer3, \n",
    "                                                      saving_path='JobFunctionModel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "O_4DgJYbUGyf",
    "outputId": "b1ece2c6-e6dc-4007-edcd-5b74be0ffc96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.load_state_dict(torch.load('JobFunctionModel.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wzA9uDaVT7yr",
    "outputId": "84d25da1-0849-408a-f4f2-e704be6cdec0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################\n",
      "OVERALL SCORES:\n",
      "recall    : 0.89\n",
      "precesion: 0.9\n",
      "f1_score    : 0.89\n",
      "\n",
      "#######################\n",
      "\n",
      "SCORES PER CLASS:\n",
      "\n",
      "\t\t\t\t recal-precision-f1_score \t no. of occurrences in dataset\n",
      "0 accounting/finance \n",
      "\t\t\t\t 0.94 \t 0.92 \t 0.93 \t\t 477\n",
      "---------------------------------------------------------------------------\n",
      "1 administration \n",
      "\t\t\t\t 0.86 \t 0.91 \t 0.89 \t\t 656\n",
      "---------------------------------------------------------------------------\n",
      "2 analyst/research \n",
      "\t\t\t\t 0.86 \t 1.0 \t 0.92 \t\t 272\n",
      "---------------------------------------------------------------------------\n",
      "3 banking \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 10\n",
      "---------------------------------------------------------------------------\n",
      "4 business development \n",
      "\t\t\t\t 0.8 \t 1.0 \t 0.89 \t\t 445\n",
      "---------------------------------------------------------------------------\n",
      "5 c-level executive/gm/director \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 3\n",
      "---------------------------------------------------------------------------\n",
      "6 creative/design/art \n",
      "\t\t\t\t 0.87 \t 1.0 \t 0.93 \t\t 739\n",
      "---------------------------------------------------------------------------\n",
      "7 customer service/support \n",
      "\t\t\t\t 0.74 \t 0.81 \t 0.77 \t\t 863\n",
      "---------------------------------------------------------------------------\n",
      "8 education/teaching \n",
      "\t\t\t\t 0.94 \t 1.0 \t 0.97 \t\t 527\n",
      "---------------------------------------------------------------------------\n",
      "9 engineering - construction/civil/architecture \n",
      "\t\t\t\t 0.71 \t 0.6 \t 0.65 \t\t 302\n",
      "---------------------------------------------------------------------------\n",
      "10 engineering - mechanical/electrical \n",
      "\t\t\t\t 0.68 \t 0.78 \t 0.73 \t\t 499\n",
      "---------------------------------------------------------------------------\n",
      "11 engineering - oil & gas/energy \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 10\n",
      "---------------------------------------------------------------------------\n",
      "12 engineering - other \n",
      "\t\t\t\t 0.38 \t 0.75 \t 0.5 \t\t 169\n",
      "---------------------------------------------------------------------------\n",
      "13 engineering - telecom/technology \n",
      "\t\t\t\t 0.95 \t 0.88 \t 0.92 \t\t 3886\n",
      "---------------------------------------------------------------------------\n",
      "14 fashion \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 3\n",
      "---------------------------------------------------------------------------\n",
      "15 hospitality/hotels/food services \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 15\n",
      "---------------------------------------------------------------------------\n",
      "16 human resources \n",
      "\t\t\t\t 0.95 \t 1.0 \t 0.97 \t\t 260\n",
      "---------------------------------------------------------------------------\n",
      "17 installation/maintenance/repair \n",
      "\t\t\t\t 0.93 \t 0.82 \t 0.87 \t\t 576\n",
      "---------------------------------------------------------------------------\n",
      "18 it/software development \n",
      "\t\t\t\t 0.97 \t 0.97 \t 0.97 \t\t 4383\n",
      "---------------------------------------------------------------------------\n",
      "19 legal \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 21\n",
      "---------------------------------------------------------------------------\n",
      "20 logistics/supply chain \n",
      "\t\t\t\t 0.85 \t 1.0 \t 0.92 \t\t 171\n",
      "---------------------------------------------------------------------------\n",
      "21 manufacturing/production \n",
      "\t\t\t\t 0.86 \t 1.0 \t 0.92 \t\t 122\n",
      "---------------------------------------------------------------------------\n",
      "22 marketing/pr/advertising \n",
      "\t\t\t\t 0.91 \t 0.85 \t 0.88 \t\t 1400\n",
      "---------------------------------------------------------------------------\n",
      "23 media/journalism/publishing \n",
      "\t\t\t\t 0.93 \t 0.77 \t 0.85 \t\t 951\n",
      "---------------------------------------------------------------------------\n",
      "24 medical/healthcare \n",
      "\t\t\t\t 0.66 \t 0.88 \t 0.75 \t\t 217\n",
      "---------------------------------------------------------------------------\n",
      "25 nan \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 117\n",
      "---------------------------------------------------------------------------\n",
      "26 operations/management \n",
      "\t\t\t\t 0.6 \t 0.82 \t 0.69 \t\t 314\n",
      "---------------------------------------------------------------------------\n",
      "27 pharmaceutical \n",
      "\t\t\t\t 0.71 \t 0.86 \t 0.77 \t\t 129\n",
      "---------------------------------------------------------------------------\n",
      "28 project/program management \n",
      "\t\t\t\t 0.93 \t 0.86 \t 0.89 \t\t 308\n",
      "---------------------------------------------------------------------------\n",
      "29 purchasing/procurement \n",
      "\t\t\t\t 1.0 \t 0.92 \t 0.96 \t\t 140\n",
      "---------------------------------------------------------------------------\n",
      "30 quality \n",
      "\t\t\t\t 0.95 \t 1.0 \t 0.97 \t\t 404\n",
      "---------------------------------------------------------------------------\n",
      "31 r&d/science \n",
      "\t\t\t\t 0.86 \t 0.86 \t 0.86 \t\t 119\n",
      "---------------------------------------------------------------------------\n",
      "32 sales/retail \n",
      "\t\t\t\t 0.97 \t 0.98 \t 0.97 \t\t 1802\n",
      "---------------------------------------------------------------------------\n",
      "33 sports and leisure \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 7\n",
      "---------------------------------------------------------------------------\n",
      "34 strategy/consulting \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 17\n",
      "---------------------------------------------------------------------------\n",
      "35 tourism/travel \n",
      "\t\t\t\t 0.0 \t 0.0 \t 0.0 \t\t 10\n",
      "---------------------------------------------------------------------------\n",
      "36 training/instructor \n",
      "\t\t\t\t 1.0 \t 0.5 \t 0.67 \t\t 135\n",
      "---------------------------------------------------------------------------\n",
      "37 writing/editorial \n",
      "\t\t\t\t 0.78 \t 1.0 \t 0.88 \t\t 202\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "test_model(model3, prob_threshold= 0.4, testLoader = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3PZR9DDeQPEp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "32INWNBLZgKX",
    "kyorXoszZL2p",
    "NzQmelnxatZc"
   ],
   "name": "job function model (3).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
